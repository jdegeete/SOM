# Config file for ReBench
# Config format is YAML (see http://yaml.org/ for detailed spec)

# this run definition will be choosen if no parameters are given to rebench.py
standard_experiment: all
standard_data_file: gc-comparison.data

reporting:
    csv_file: latest-runs.csv
    csv_locale: de_DE.UTF-8

runs:
    number_of_data_points: 10

statistics:
    confidence_level: 0.95
 
# settings for quick runs, useful for fast feedback during experiments
quick_runs:
    number_of_data_points: 3
    max_time: 60   # time in seconds

# definition of benchmark suites
benchmark_suites:
    macro:
        gauge_adapter: RebenchLog
        command: ":Examples/Benchmarks/Richards:Examples/Benchmarks/DeltaBlue Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        max_runtime: 600
        benchmarks:
            - Richards:
                extra_args: "1 0 10   %(cores)s"
            - DeltaBlue:
                extra_args: "1 0 6000 %(cores)s"

    micro:
        gauge_adapter: RebenchLog
        command: " Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        max_runtime: 200000
        benchmarks:
            - Fibonacci:
                extra_args: "1 0 3   %(cores)s"
            - Dispatch:
                extra_args: "1 0 20  %(cores)s"
            - Bounce:
                extra_args: "1 0 2   %(cores)s"
            - Loop:
                extra_args: "1 0 10  %(cores)s"
            - Permute:
                extra_args: "1 0 3   %(cores)s"
            - Queens:
                extra_args: "1 0 2   %(cores)s"
            - List:
                extra_args: "1 0 2   %(cores)s"
            - Recurse:
                extra_args: "1 0 3   %(cores)s"
            - Storage:
                extra_args: "1 0 2   %(cores)s"
            - Sieve:
                extra_args: "1 0 5   %(cores)s"
            - BubbleSort:
                extra_args: "1 0 3   %(cores)s"
            - QuickSort:
                extra_args: "1 0 3   %(cores)s"
            - Sum:
                extra_args: "1 0 10  %(cores)s"
            - Towers:
                extra_args: "1 0 2   %(cores)s"
            - TreeSort:
                extra_args: "1 0 1   %(cores)s"
            - IntegerLoop:
                extra_args: "1 0 8   %(cores)s"
            - FieldLoop:
                extra_args: "1 0 3   %(cores)s"
            - WhileLoop:
                extra_args: "1 0 30  %(cores)s"

# VMs have a name and are specified by a path and the binary to be executed
virtual_machines:
    SOMpp:
        path: .
        binary: som.sh
        args: "-cp Smalltalk"
        cores: [1, 2]
        
# define the benchmarks to be executed for a re-executable benchmark run
experiments:
    SOM:
        actions: benchmark
        benchmark:
            - micro
            - macro
        executions: 
            - SOMpp

